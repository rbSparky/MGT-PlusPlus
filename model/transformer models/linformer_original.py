
# original:

# RESULT ON QMOF 
# Epoch loss: 54.5266
# Training time: 69.36584162712097 seconds
# Validation error: 5.5961
# Validation time: 10.028708219528198 seconds
# Completed Epoch 1 of 100 in 79.39 s
# /home/rishabh/miniconda3/envs/mgt_py310/lib/python3.10/site-packages/torch/distributed/fsdp/_state_dict_utils.py:768: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.
#   warnings.warn(
# /home/rishabh/miniconda3/envs/mgt_py310/lib/python3.10/site-packages/torch/distributed/fsdp/_state_dict_utils.py:711: UserWarning: When using ``NO_SHARD`` for ``ShardingStrategy``, full_state_dict willbe returned.
#   warnings.warn(
# Epoch loss: 21.2292
# Training time: 60.45105218887329 seconds
# Validation error: 2.3921
# Validation time: 8.08532428741455 seconds
# Completed Epoch 2 of 100 in 68.54 s
# Epoch loss: 3.7909
# Training time: 67.24340653419495 seconds
# Validation error: 0.9672
# Validation time: 7.367536306381226 seconds
# Completed Epoch 3 of 100 in 74.61 s
# Epoch loss: 13.3566
# Training time: 84.10680294036865 seconds
# Validation error: 2.7279
# Validation time: 7.884578466415405 seconds
# Completed Epoch 4 of 100 in 91.99 s
# Epoch loss: 14.7052
# Training time: 78.59509038925171 seconds
# Validation error: 2.4391
# Validation time: 9.91873836517334 seconds
# Completed Epoch 5 of 100 in 88.51 s
# Epoch loss: 6.9281
# Training time: 70.71161341667175 seconds
# Validation error: 1.6733
# Validation time: 7.125887870788574 seconds
# Completed Epoch 6 of 100 in 77.84 s
# Epoch loss: 1.1719
# Training time: 65.1536602973938 seconds
# Validation error: 0.3617
# Validation time: 3.8275842666625977 seconds
# Completed Epoch 7 of 100 in 68.98 s
# Epoch loss: 1.6374
# Training time: 51.80331897735596 seconds
# Validation error: 1.0167
# Validation time: 3.6224591732025146 seconds
# Completed Epoch 8 of 100 in 55.43 s
# Epoch loss: 5.5910
# Training time: 49.90553689002991 seconds
# Validation error: 1.8246
# Validation time: 3.8214111328125 seconds
# Completed Epoch 9 of 100 in 53.73 s
# Epoch loss: 7.8160
# Training time: 48.67223930358887 seconds
# Validation error: 1.9164
# Validation time: 6.0077996253967285 seconds
# Completed Epoch 10 of 100 in 54.68 s
# Epoch loss: 6.4284
# Training time: 55.73936057090759 seconds
# Validation error: 1.6463
# Validation time: 7.189860582351685 seconds
# Completed Epoch 11 of 100 in 62.93 s
# Epoch loss: 3.1711
# Training time: 67.71444153785706 seconds
# Validation error: 1.1613
# Validation time: 6.21182107925415 seconds
# Completed Epoch 12 of 100 in 73.93 s
# Epoch loss: 0.7859
# Training time: 66.08871555328369 seconds
# Validation error: 0.4779
# Validation time: 6.2915358543396 seconds
# Completed Epoch 13 of 100 in 72.38 s
# Epoch loss: 0.6121
# Training time: 63.62218618392944 seconds
# Validation error: 0.6067
# Validation time: 6.737773895263672 seconds
# Completed Epoch 14 of 100 in 70.36 s
# Epoch loss: 2.0448
# Training time: 61.00392985343933 seconds
# Validation error: 0.9195
# Validation time: 6.069150447845459 seconds
# Completed Epoch 15 of 100 in 67.07 s
# Epoch loss: 3.1415
# Training time: 68.05798053741455 seconds
# Validation error: 1.2948
# Validation time: 6.86466383934021 seconds
# Completed Epoch 16 of 100 in 74.92 s
# Epoch loss: 3.0213
# Training time: 59.48302602767944 seconds
# Validation error: 0.9392
# Validation time: 6.953159332275391 seconds
# Completed Epoch 17 of 100 in 66.44 s
# Epoch loss: 1.8675
# Training time: 62.303004026412964 seconds
# Validation error: 0.7240
# Validation time: 6.118061065673828 seconds
# Completed Epoch 18 of 100 in 68.42 s
# Epoch loss: 0.7007
# Training time: 63.34887981414795 seconds
# Validation error: 0.4004
# Validation time: 7.0461249351501465 seconds
# Completed Epoch 19 of 100 in 70.40 s
# Epoch loss: 0.4197
# Training time: 64.26527214050293 seconds
# Validation error: 0.4044
# Validation time: 6.839988470077515 seconds
# Completed Epoch 20 of 100 in 71.11 s
# Epoch loss: 0.6302
# Training time: 67.9052951335907 seconds
# Validation error: 0.5963
# Validation time: 6.026792049407959 seconds
# Completed Epoch 21 of 100 in 73.93 s
# Epoch loss: 1.1356
# Training time: 67.58934020996094 seconds
# Validation error: 0.6428
# Validation time: 6.7410266399383545 seconds
# Completed Epoch 22 of 100 in 74.33 s
# Epoch loss: 1.3212
# Training time: 65.04762363433838 seconds
# Validation error: 0.9483
# Validation time: 6.923737049102783 seconds
# Completed Epoch 23 of 100 in 71.97 s
# Epoch loss: 1.1444
# Training time: 63.59297323226929 seconds
# Validation error: 0.8635
# Validation time: 7.304357528686523 seconds
# Completed Epoch 24 of 100 in 70.90 s
# Epoch loss: 0.7693
# Training time: 60.23597502708435 seconds
# Validation error: 0.5533
# Validation time: 6.094843149185181 seconds
# Completed Epoch 25 of 100 in 66.33 s
# Epoch loss: 0.4560
# Training time: 59.02282691001892 seconds
# Validation error: 0.3800
# Validation time: 6.992708683013916 seconds
# Completed Epoch 26 of 100 in 66.02 s
# Epoch loss: 0.3021
# Training time: 65.49478697776794 seconds
# Validation error: 0.4051
# Validation time: 7.084593296051025 seconds
# Completed Epoch 27 of 100 in 72.58 s
# Epoch loss: 0.4396
# Training time: 62.26750588417053 seconds
# Validation error: 0.5161
# Validation time: 6.965347766876221 seconds
# Completed Epoch 28 of 100 in 69.23 s
# Epoch loss: 0.7127
# Training time: 65.22490191459656 seconds
# Validation error: 0.5920
# Validation time: 6.833177328109741 seconds
# Completed Epoch 29 of 100 in 72.06 s
# Epoch loss: 0.7203
# Training time: 62.56430459022522 seconds
# Validation error: 0.3890
# Validation time: 6.973329067230225 seconds
# Completed Epoch 30 of 100 in 69.54 s
# Epoch loss: 0.6040
# Training time: 63.213244676589966 seconds
# Validation error: 0.4340
# Validation time: 6.177328109741211 seconds
import math
from typing import Union, Tuple, Optional
import dgl
import torch
import dgl.function as fn
import torch.nn.functional as F
from torch import nn
from dgl import softmax_edges
from dgl.nn.functional import edge_softmax

class multiheaded(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, heads: int = 1, concat: bool = True, dropout: float = 0.2, bias: bool = True, residual: bool = True, norm: Union[bool, Tuple[bool, bool]] = True):
        super(multiheaded, self).__init__()
        if isinstance(norm, bool):
            norm = (norm, norm)
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.heads = heads
        self.concat = concat
        self.dropout = dropout
        self.residual = residual
        self.norm = norm
        self.lin_query = nn.Linear(in_channels, heads * out_channels, bias=bias)
        self.lin_key = nn.Linear(in_channels, heads * out_channels, bias=bias)
        self.lin_value = nn.Linear(in_channels, heads * out_channels, bias=bias)
        self.lin_edge = nn.Linear(in_channels, heads * out_channels, bias=bias)
        if self.concat:
            if self.norm[0]:
                self.norm_node = nn.LayerNorm(heads * out_channels)
            if self.norm[1]:
                self.norm_edge = nn.LayerNorm(heads * out_channels)
        else:
            if self.norm[0]:
                self.norm_node = nn.LayerNorm(out_channels)
            if self.norm[1]:
                self.norm_edge = nn.LayerNorm(out_channels)
        self.reset_parameters()

    def reset_parameters(self):
        self.lin_query.reset_parameters()
        self.lin_key.reset_parameters()
        self.lin_value.reset_parameters()
        if self.lin_edge is not None:
            self.lin_edge.reset_parameters()

    def forward(self, g: dgl.DGLGraph, node_feats: torch.Tensor, edge_feats: torch.Tensor):
        g = g.local_var()
        g.ndata['query'] = self.lin_query(node_feats).view(-1, self.heads, self.out_channels)
        g.ndata['key'] = self.lin_key(node_feats).view(-1, self.heads, self.out_channels)
        g.ndata['value'] = self.lin_value(node_feats).view(-1, self.heads, self.out_channels)
        g.apply_edges(fn.u_mul_v('query', 'key', 'scores'))
        m = g.edata.pop('scores') + self.lin_edge(edge_feats).view(-1, self.heads, self.out_channels)
        scores = m / math.sqrt(self.out_channels)
        g.edata['alpha'] = F.dropout(edge_softmax(g, scores).sum(dim=-1).unsqueeze(dim=-1), p=self.dropout)
        g.update_all(fn.u_mul_e('value', 'alpha', 'm'), fn.sum('m', 'h'))
        x = g.ndata.pop('h')
        if self.concat:
            x = x.view(-1, self.heads * self.out_channels)
            m = m.view(-1, self.heads * self.out_channels)
        else:
            x = x.mean(dim=1)
            m = m.mean(dim=1)
        if self.norm[0]:
            x = self.norm_node(x)
        if self.norm[1]:
            m = self.norm_edge(m)
        if self.residual:
            x += node_feats
            y = m + edge_feats
        return x, y
